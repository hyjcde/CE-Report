% !TEX root = ../thesis.tex

\chapter{Literature Review} \label{chp:literature}

\section{Evolution of Diagnostic Imaging Technologies for Gastrointestinal Tumors}

\subsection{From Traditional X-ray to Modern Cross-sectional Imaging}

The history of diagnostic imaging for gastrointestinal tumors represents a continuous evolution of technological innovation and progressive improvement in diagnostic precision. The earliest diagnostic approaches relied on upper gastrointestinal barium contrast studies and other X-ray techniques, which inferred the presence of lesions through indirect signs such as filling defects and mucosal destruction. However, these methods suffered from low spatial resolution, extremely poor detection rates for early flat or small lesions, and substantial dependence on operator experience. The advent of computed tomography (CT) technology marked the first opportunity to observe abdominal organs in cross-sectional format without overlapping structures, dramatically improving the assessment of tumor size, morphology, and relationships with surrounding tissues. Functional CT techniques such as perfusion imaging also provided additional information for differentiating benign from malignant tumors.

Subsequently, magnetic resonance imaging (MRI), particularly with the application of functional sequences like diffusion-weighted imaging (DWI), demonstrated unique advantages in qualitative tumor diagnosis and staging through its superior soft tissue resolution and sensitivity to cellular density. Endoscopic ultrasound (EUS) revolutionized the field by placing high-frequency transducers within the digestive tract lumen, achieving exquisite visualization of wall layers and adjacent organs, establishing itself as the gold standard for assessing tumor invasion depth (T staging) and regional lymph node status (N staging). However, as previously discussed, these technological advances primarily concentrated on "problem-solving" rather than "problem-finding" phases of diagnosis. Their inherent limitations related to cost, radiation exposure, or invasiveness prevent them from assuming the crucial role of first-line screening, creating a persistent gap between technological capability and clinical need.

\subsection{Ultrasound Technology Development: From A-mode to Real-time Three-dimensional Imaging}

Ultrasound medicine, as an independent imaging discipline, has undergone tremendous transformation from one-dimensional to three-dimensional capabilities, from static to dynamic imaging, and from morphological to functional assessment. The earliest A-mode (amplitude modulation) ultrasound could only provide one-dimensional distance and echo intensity information. The emergence of B-mode (brightness modulation) ultrasound first converted echo signals into two-dimensional grayscale images, establishing the foundation for modern ultrasound diagnosis. The introduction of Doppler technology enabled blood flow detection, with color Doppler and power Doppler greatly enriching the assessment tools for lesion vascularity, which is crucial for tumor differential diagnosis.

Recent years have witnessed the emergence of advanced technologies including contrast-enhanced ultrasound (CEUS), elastography, and real-time three-dimensional/four-dimensional imaging, further enhancing ultrasound diagnostic capabilities across multiple dimensions including blood flow perfusion patterns, tissue stiffness, and spatial morphology. Despite these technological advances, all sophisticated ultrasound techniques have failed to fundamentally resolve a core issue: they remain "tools" whose value realization ultimately depends on the operator's "hands" and "eyes." This dependence on human operators represents the underlying logic that has remained unchanged throughout ultrasound technology development and constitutes the fundamental starting point for this research's attempt to assist and enhance human capabilities through AI. The persistence of operator dependence despite technological advancement highlights the unique position of ultrasound among medical imaging modalities and the particular relevance of AI assistance in this domain.

\section{Applications of Artificial Intelligence in Medical Image Analysis}

\subsection{The Machine Learning and Radiomics Era}

The application of artificial intelligence in medical image analysis can be traced back to early expert systems in the 1980s, but genuine breakthroughs began with the maturation of machine learning technologies in the early 21st century. Traditional machine learning methods, such as support vector machines (SVM) and random forests, required researchers to manually design features. While these methods achieved certain success in specific tasks, they were limited by the quality of feature engineering and data complexity. The concept of radiomics emerged in this context, attempting to extract large quantities of quantitative features from medical images, including shape, texture, and density characteristics, and establish correlative models with clinical endpoints through machine learning algorithms.

Radiomics methods demonstrated potential in diagnosis, staging, and prognostic prediction across multiple cancer types, particularly in utilizing existing high-resolution images from CT and MRI. However, the success of radiomics largely depended on precise lesion segmentation and standardized image acquisition conditions, which are often difficult to guarantee in ultrasound imaging. The operator dependence of ultrasound images, variability in image quality, and lack of standardized acquisition protocols significantly limited the application of traditional radiomics methods in the ultrasound domain. This limitation highlighted the need for approaches specifically designed to handle the unique characteristics of ultrasound imaging, setting the stage for deep learning innovations that could address these challenges through end-to-end learning rather than relying on handcrafted features.

\subsection{The Deep Learning Revolution: Convolutional Neural Networks and Their Variants}

The breakthrough performance of AlexNet in the 2012 ImageNet competition marked the arrival of the deep learning era and brought revolutionary changes to medical image analysis. Convolutional neural networks (CNNs) can automatically learn hierarchical feature representations, from low-level edges and textures to high-level semantic concepts. This end-to-end learning approach avoided the subjectivity and limitations of manual feature design. In the medical imaging field, CNNs and their variants such as ResNet, DenseNet, and U-Net rapidly achieved remarkable results across various tasks including image classification, object detection, and semantic segmentation.

In ultrasound image analysis, CNNs demonstrated unique advantages in processing complex textures and low-contrast images. Compared to traditional methods, deep learning models better adapted to the noise, artifacts, and variability of ultrasound images, providing new tools for addressing challenges in ultrasound diagnosis. However, CNN applications in the ultrasound field also faced challenges including data scarcity, annotation difficulties, and model generalization issues, particularly for relatively rare diseases like gastric and pancreatic cancers where high-quality annotated data was especially scarce. These challenges necessitated innovative approaches to training and validation that could maximize the utility of limited data while ensuring robust performance across diverse clinical scenarios.

\subsection{The Rise of Transformer Architectures in Visual Tasks}

The introduction of Vision Transformer (ViT) in 2020 brought the Transformer architecture, which had achieved tremendous success in natural language processing, into the computer vision domain. Unlike CNNs with local receptive fields, Transformers can capture global contextual information through self-attention mechanisms, which has unique value in medical image analysis, particularly in tasks requiring integration of information from multiple anatomical regions. Subsequently emerging hybrid architectures such as ConvNeXt and MaxViT attempted to combine the local feature extraction capabilities of CNNs with the global modeling capabilities of Transformers.

In ultrasound image analysis, the global modeling capability of Transformer architectures provides new possibilities for solving anatomical relationship modeling between organs. For example, in upper abdominal ultrasound examination, the relative positions and interactions of organs such as stomach, pancreas, and liver are crucial for accurate diagnosis, while traditional CNN local processing approaches might struggle to effectively capture these long-range dependencies. The unified framework proposed in this research hopes to utilize this global modeling capability of Transformers to achieve synergistic assessment of stomach and pancreas. This approach represents a natural evolution from local feature analysis toward holistic understanding of anatomical relationships and pathological interactions.

\section{Specific Challenges and Advances in Deep Learning for Ultrasound Image Analysis}

\subsection{Challenges from Physical Properties of Ultrasound Images}

Ultrasound images possess unique physical characteristics that are both their strengths and the main challenges that AI algorithms need to overcome. Firstly, low signal-to-noise ratio is an inherent feature of ultrasound images. Sound waves undergo attenuation, scattering, and absorption during propagation through human tissue, resulting in substantial speckle noise in images. This noise is not simple Gaussian noise but multiplicative noise related to tissue microstructure, making traditional denoising methods often ineffective. Secondly, various artifacts easily occur during ultrasound imaging, including reverberation artifacts, side lobe artifacts, and multipath artifacts. These artifacts may be mistaken for pathological structures or mask real lesions.

Anisotropy represents another important characteristic of ultrasound images, meaning that image resolution is non-uniform in different directions, with axial resolution typically superior to lateral resolution. This characteristic requires AI algorithms to consider this asymmetry during design. Furthermore, ultrasound image contrast and brightness heavily depend on factors such as the angle between the sound beam and tissue interfaces, tissue acoustic properties, and system gain settings. This variability makes model generalization challenging. Recent years have seen researchers beginning to develop deep learning algorithms specifically targeting these characteristics of ultrasound images, including designing specialized network architectures, loss functions, and data augmentation strategies. These efforts represent important steps toward creating ultrasound-specific AI solutions that can handle the unique challenges of this imaging modality.

\subsection{Current Research Status: Applications in Thyroid, Breast, and Liver Organs}

Currently, AI applications in ultrasound image analysis primarily concentrate on thyroid, breast, and liver organs, areas that have achieved relatively mature research results. In thyroid ultrasound AI, multiple studies have shown that deep learning models can achieve or even surpass the performance of experienced physicians in differentiating benign from malignant thyroid nodules, with some commercial products beginning clinical application. Breast ultrasound AI research is equally active, particularly in breast mass detection and BI-RADS classification, where AI systems have demonstrated good performance. Liver ultrasound AI mainly focuses on diagnosing liver diseases, including detection and assessment of fatty liver, liver fibrosis, and liver cancer.

These successful applications provide valuable experience for ultrasound AI development while also revealing some limitations of current research. Most studies focus on single-organ, single-disease specialized models, lacking cross-organ, cross-disease generalization capabilities. Existing research mainly concerns static image analysis while ignoring temporal information from dynamic ultrasound scanning. Most models can only provide diagnostic results without offering diagnostic reasoning processes or confidence assessments like experienced physicians. Finally, existing research generally lacks deep integration with clinical workflows, mostly remaining at the offline validation stage with significant distance from genuine clinical application. These limitations highlight the need for more comprehensive approaches that consider the full spectrum of clinical requirements and workflow integration challenges.

\section{AI Research Status Focused on Gastric and Pancreatic Cancers}

\subsection{EUS-based AI Research}

Endoscopic ultrasound (EUS), as an important tool for diagnosing gastric and pancreatic cancers, has also become a hot area for AI research in recent years. EUS-based AI research mainly concentrates on early diagnosis and T-staging assessment of pancreatic cancer. Multiple studies have shown that deep learning models can accurately identify pancreatic cancer in EUS images, with some studies reporting AUC values exceeding 0.9. For gastric cancer, EUS-based AI research is relatively limited, mainly focusing on detection of early gastric cancer and assessment of invasion depth. Some studies have attempted to use EUS fine-needle aspiration (FNA) images for AI-assisted cytological diagnosis.

However, EUS-based AI research faces challenges including difficult data acquisition, complex annotation, and limited clinical application. As an invasive examination, EUS data is relatively scarce and requires highly specialized physicians for operation and interpretation. Additionally, EUS image quality and viewing angles heavily depend on operator skills, increasing the complexity of model training and validation. Most importantly, EUS cannot serve as a first-line screening tool, limiting its application value in early diagnosis. These limitations underscore the importance of developing AI solutions for less invasive imaging modalities that can serve broader screening applications, highlighting the strategic value of transabdominal ultrasound AI development.

\subsection{CT/MRI-based AI Research}

CT/MRI-based gastric and pancreatic cancer AI research is relatively mature, mainly benefiting from the higher standardization and relatively stable image quality of these imaging technologies. For pancreatic cancer, multiple studies have shown that AI models can accurately detect pancreatic cancer in CT images and perform TNM staging assessment. Some studies have also attempted to use AI to predict pancreatic cancer resectability and prognosis. For gastric cancer, CT-based AI research mainly focuses on tumor detection, staging, and treatment response assessment. MRI application in gastric cancer diagnosis is relatively limited but shows potential in assessing tumor invasion depth and lymph node metastasis.

While these studies have achieved good results in technical metrics, they still face challenges in clinical translation. CT/MRI high costs and radiation risks prevent their use for large-scale screening. Most studies are based on retrospective data, lacking prospective validation. Existing models often focus only on technical performance metrics while ignoring the actual value of clinical decision-making. Finally, these studies are mostly single-center, small-sample studies with model generalizability yet to be verified. These limitations reinforce the need for screening-appropriate imaging modalities and highlight the potential value of enhancing transabdominal ultrasound capabilities through AI assistance.

\subsection{Transabdominal Ultrasound-based AI Research: Still in Early Stages with Scattered Results}

Compared to EUS and CT/MRI, gastric and pancreatic cancer AI research based on transabdominal ultrasound remains in early stages with relatively scattered results. Existing limited studies mainly concentrate on pancreatic cancer detection, training deep learning models to identify pancreatic masses using transabdominal ultrasound images. Some studies have attempted to use texture features and morphological features from ultrasound images to differentiate benign from malignant pancreatic lesions. For gastric cancer, transabdominal ultrasound-based AI research is even more sparse, mainly because gastric ultrasound examination is relatively uncommon in clinical practice and technically challenging.

This research status has formed due to multiple factors. Firstly, the operator dependence of transabdominal ultrasound makes data standardization and quality control difficult. Secondly, gastric and pancreatic cancers have relatively subtle imaging manifestations on transabdominal ultrasound, increasing the difficulty of AI model learning. Furthermore, existing research lacks support from large-scale, high-quality datasets. Finally, the absence of unified evaluation standards and clinical validation methods makes it difficult to compare and verify different studies. These challenges create both obstacles and opportunities for this research, as successfully addressing these limitations could yield significant clinical impact.

\subsection{Knowledge Gap Identification I: Prevalence and Limitations of the "Single-Task, Single-Model" Paradigm}

Through systematic review of existing literature, we identify the first important knowledge gap: the prevalence and limitations of the "single-task, single-model" paradigm. Currently, the vast majority of AI research adopts this paradigm, training independent specialized models for each specific diagnostic task such as gastric cancer detection, pancreatic cancer segmentation, or benign-malignant differentiation. While this approach may achieve good performance on individual tasks, it has several limitations. It severs anatomical relationships and pathological associations between organs, failing to utilize synergistic information between stomach and pancreas. This approach leads to resource duplication and model fragmentation, increasing clinical deployment complexity.

Furthermore, single-task models often lack contextual understanding capabilities, unable to perform holistic assessments like experienced physicians. Finally, this approach limits cross-task knowledge transfer, with new tasks often requiring training from scratch, resulting in low efficiency. Therefore, there is an urgent need to explore unified frameworks capable of handling multi-organ, multi-task processing, which is one of the core motivations of this research. The limitations of current approaches create a clear opportunity for innovation in unified modeling approaches that can capture and utilize the natural relationships between anatomically and pathologically related organs.

\section{Cutting-edge Exploration of Unified Models and Multi-task Learning}

\subsection{Theoretical Foundations and Advantages of Multi-Task Learning}

Multi-task learning (MTL), as an important branch of machine learning, has the core idea of improving individual task performance by simultaneously learning multiple related tasks. The theoretical foundation of MTL can be traced back to human learning cognitive mechanisms where humans often utilize existing knowledge and experience when learning new skills. Knowledge transfer between related tasks can accelerate the learning process and improve final performance. Under the deep learning framework, MTL achieves cross-task knowledge transfer through sharing bottom-layer representations of networks, enabling models to learn more robust and generalizable feature representations.

The advantages of MTL are mainly reflected in several aspects. Data efficiency improvement allows MTL to train effective models even when individual task data is scarce by utilizing data from multiple tasks. Generalization capability enhancement occurs because shared representation learning forces models to focus on common features between tasks rather than overfitting to task-specific features, thereby improving model generalization. Computational resource savings result from significant reduction in total parameters and computational overhead through parameter sharing compared to training multiple independent models. Regularization effects arise because joint training of multiple tasks is equivalent to implicit regularization, helping prevent overfitting. These advantages make MTL particularly suitable for medical imaging applications where data scarcity and the need for robust generalization are common challenges.

\subsection{Advanced Training Strategies Including Knowledge Distillation and Self-supervised Learning}

Beyond traditional multi-task learning, recent years have seen the emergence of various advanced training strategies that provide new tools for building more powerful unified models. Knowledge distillation achieves dual goals of model compression and knowledge transfer by having small models (students) learn from large models (teachers). In the context of this research, knowledge distillation can be used to integrate knowledge from multiple expert models into a unified framework or transfer knowledge from large-scale pre-trained models to specific medical domains.

Self-supervised learning (SSL) learns powerful feature representations by designing clever pre-training tasks that utilize large-scale unlabeled data. In the medical imaging field, SSL is particularly valuable because obtaining high-quality medical image annotations is often expensive and time-consuming. Contrastive learning and masked image modeling self-supervised methods have achieved significant success in natural images and are beginning to show potential in medical imaging. The "Two-Stage Knowledge Injection" strategy proposed in this research draws inspiration from self-supervised learning, first utilizing large-scale weakly-labeled or unlabeled abdominal ultrasound data for pre-training. This approach represents a natural evolution toward more efficient utilization of available data resources in medical AI development.

\subsection{Knowledge Gap Identification II: Lack of Unified Frameworks Designed for Ultrasound Heterogeneous Data Characteristics}

Through in-depth analysis of multi-task learning and unified model literature, we identify the second important knowledge gap: existing unified frameworks are mostly designed for natural images or other medical imaging modalities, lacking specialized design considerations for ultrasound heterogeneous data characteristics. Ultrasound images possess unique physical properties including anisotropic resolution, complex noise patterns, and high operator dependence, which require special consideration during AI framework design.

Existing unified frameworks often assume input data with relatively consistent quality and format, which clearly does not hold in the ultrasound domain. The heterogeneity of ultrasound data is reflected not only in image quality variations but also in scanning perspectives, organ visualization degrees, and annotation granularity across multiple aspects. For example, in upper abdominal ultrasound examination, gastric display may be incomplete due to gas interference, and pancreatic visualization may vary greatly depending on body habitus and intestinal gas. This data heterogeneity brings unique challenges to unified modeling. Therefore, there is an urgent need to develop unified frameworks specifically designed for ultrasound data characteristics, which is one of the core contributions of this research. Such frameworks must be robust to the inherent variability of ultrasound imaging while maintaining high performance across diverse clinical scenarios.

\section{Methodological Research on Clinical Validation of AI Models}

\subsection{From Technical Metrics to Clinical Utility Indicators}

Traditional AI model evaluation mainly relies on technical performance metrics such as accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC). While these metrics can objectively measure model classification performance, they often cannot directly reflect the model's true value in clinical practice. Clinical decision-making is a complex process involving comprehensive consideration of multiple factors including diagnostic accuracy, treatment benefit-risk ratios, patient preferences, and medical resource allocation. Pure technical metrics often ignore the complexity of clinical decision-making.

Recent years have seen the medical AI field beginning to emphasize the development and application of clinical utility indicators. These indicators attempt to more directly measure AI model impact on clinical decisions and patient outcomes. For example, diagnostic impact assesses the degree of AI recommendation influence on final diagnosis, treatment change measures AI recommendation impact on treatment option selection, and clinical outcomes directly evaluate AI application improvement in patient health outcomes. This shift from technical metrics to clinical utility indicators reflects an important transformation in medical AI research from technology-oriented to clinical value-oriented approaches. This evolution recognizes that technical excellence alone is insufficient without demonstrable clinical benefit and real-world applicability.

\subsection{Application and Value of Decision Curve Analysis}

Decision curve analysis (DCA) is a widely applied method in medical prediction model evaluation in recent years that evaluates model clinical value by quantifying net benefit under different decision thresholds. The core idea of DCA is to compare net benefits of different strategies including using prediction models versus not using models (defaulting to treating all patients or treating none) under different risk thresholds. Net benefit considers benefits from true positives and harm from false positives, providing a model evaluation perspective that is closer to clinical reality.

In the context of this research, DCA is particularly valuable because gastric and pancreatic cancer diagnosis involves major clinical decisions. While early diagnosis can significantly improve patient prognosis, overdiagnosis may also lead to unnecessary anxiety, additional examinations, and treatment risks. DCA can help us quantify net benefits of using AI-assisted diagnosis compared to traditional methods under different risk thresholds, providing more valuable information for clinical decision-making. This research plans to incorporate DCA analysis in the multi-dimensional validation system to comprehensively evaluate the clinical value of the proposed unified framework. DCA represents a critical tool for bridging the gap between technical performance and clinical utility, ensuring that AI development efforts focus on meaningful clinical outcomes rather than abstract metrics.

\subsection{Knowledge Gap Identification III: Lack of Deep Linkage with Pathological Gold Standards and Clinical Decision-making}

Through systematic review of AI model clinical validation methodology, we identify the third important knowledge gap: existing ultrasound AI research generally lacks deep linkage with pathological gold standards and clinical decision-making. Most research validation still remains at the imaging annotation level, comparing AI predictions with imaging physician annotations, rarely directly comparing AI predictions with final pathological diagnosis or clinical outcomes. This validation approach has two main problems. Imaging physician annotations themselves may contain errors, and using them as "gold standards" may underestimate or overestimate AI true performance.

Furthermore, imaging diagnostic accuracy does not equate to clinical value. An AI model that performs excellently on imaging annotations may not necessarily provide valuable assistance in actual clinical decision-making. Pathological diagnosis, as the ultimate gold standard for tumor diagnosis, should become an important reference for AI model validation. Additionally, existing research often ignores AI prediction impact on clinical decision pathways, lacking systematic evaluation of AI-assisted diagnosis value in improving patient management and optimizing resource allocation. This research will establish a "technical-clinical-decision" tripartite validation system precisely to fill this important knowledge gap. Such comprehensive validation approaches are essential for ensuring that AI development efforts translate into meaningful clinical benefits rather than remaining academic exercises with limited real-world impact.

\section{Human-Computer Interaction and Workflow Integration in Medical Fields}

\subsection{Design Principles of Clinical Decision Support Systems}

Clinical decision support systems (CDSS), as important applications of medical AI, have design principles that directly affect the acceptance and effectiveness of AI technology in clinical practice. Successful CDSS typically follow several core design principles. Non-intrusiveness means systems should seamlessly integrate into existing clinical workflows rather than forcing physicians to change established work habits. Overly abrupt or complex interfaces often cause physician resistance, affecting system adoption. Explainability requires physicians to understand the basis and logic of AI recommendations, as blind "black box" recommendations often struggle to gain clinical physician trust.

Context-awareness means excellent CDSS should understand current clinical situations including specific patient conditions, examination purposes, and physician professional backgrounds, thereby providing personalized recommendations. Progressive intelligence augmentation means systems should provide different levels of assistance based on physician experience levels and preferences, from simple reminders to complex decision recommendations. The Sono-Agent prototype proposed in this research is based on these design principles, aiming to build a truly useful and welcomed clinical AI assistant. These principles reflect decades of research in human-computer interaction and clinical informatics, emphasizing the importance of user-centered design in medical AI development.

\subsection{Opportunities and Risks of Generative AI in Medical Report Generation}

The rapid development of large language models and generative AI provides new possibilities for automatic medical report generation. These technologies can generate fluent, professional medical report text based on imaging findings, clinical information, and other inputs, significantly improving report writing efficiency. In the ultrasound field, report generation AI value is particularly prominent because ultrasound examinations often involve substantial real-time observation and subjective judgment, making the transformation of this information into standardized report text a time-consuming and error-prone process.

However, generative AI in medical report generation also faces unique risks, with "AI hallucination" being the most prominent problem. AI hallucination refers to models generating seemingly reasonable but actually inaccurate or evidence-unsupported content. In the medical field, such hallucinations may lead to serious consequences including misdiagnosis, inappropriate treatment, or medical disputes. To address this problem, researchers have proposed various strategies including retrieval-augmented generation, fact-checking mechanisms, and human-AI collaborative report generation. This research pays special attention to this problem in the Sono-Agent prototype, proposing knowledge-enhanced intelligent report generation methods that introduce medical knowledge graphs for fact-checking to ensure generated content reliability. This approach represents a critical step toward safe and reliable AI-assisted clinical documentation.

\subsection{Knowledge Gap Identification IV: Lack of Collaborative Intelligence Interaction Paradigms Designed Specifically for Dynamic Ultrasound Scanning}

Through in-depth analysis of human-computer interaction and workflow integration literature, we identify the fourth important knowledge gap: existing medical AI interaction systems are mostly designed for static imaging and standardized workflows, lacking collaborative intelligence interaction paradigms designed specifically for dynamic ultrasound scanning. Ultrasound examination has highly dynamic and interactive characteristics, with physicians needing to continuously adjust probe positions, change scanning angles, and decide next examination strategies based on real-time observations. This dynamic, adaptive examination process fundamentally differs from static image analysis.

Existing AI systems often assume predetermined, standardized image inputs while ignoring the dynamism and interactivity of ultrasound examination. Additionally, ultrasound physicians often rely on integration of multiple sensory information during scanning, including visual and tactile feedback, which is also difficult for existing AI systems to handle. Therefore, there is an urgent need to develop collaborative intelligence interaction paradigms specifically designed for dynamic ultrasound scanning characteristics. Such paradigms should provide real-time, context-relevant intelligent assistance during examination while maintaining respect for physician decision autonomy. The Sono-Agent proposed in this research aims to fill this gap. This represents a significant opportunity for innovation in medical AI interface design and human-computer collaboration.

\section{Research Positioning and Starting Point Summary}

Through the above systematic literature review, we clearly identify four important knowledge gaps that collectively constitute the theoretical foundation and practical motivation of this research. The prevalence and limitations of the "single-task, single-model" paradigm reveal the necessity of constructing unified computational frameworks. Existing AI research lacks utilization of synergistic effects between gastric and pancreatic cancers, which not only limits diagnostic performance improvement but also increases clinical deployment complexity. The USANet unified framework proposed in this research aims to break through the limitations of this paradigm and achieve genuine synergistic intelligence.

The lack of unified frameworks designed for ultrasound heterogeneous data characteristics exposes the inadequacy of existing methods in handling ultrasound data. The unique physical properties and high variability of ultrasound images require specialized design considerations for AI frameworks, while existing general frameworks often cannot effectively handle these challenges. The "Two-Stage Knowledge Injection" training strategy proposed in this research specifically considers the special properties of ultrasound data. This approach acknowledges the fundamental differences between ultrasound and other imaging modalities while providing a pathway for robust model development.

The general lack of deep linkage with pathological gold standards and clinical decision-making in existing research limits accurate assessment of AI model clinical value. The "technical-clinical-decision" tripartite validation system established in this research aims to more comprehensively and accurately evaluate AI framework clinical value, particularly through decision curve analysis to quantify net benefits in clinical decision-making. This comprehensive validation approach represents a critical advancement toward evidence-based AI development that prioritizes clinical utility over technical metrics alone.

Finally, the lack of collaborative intelligence interaction paradigms designed specifically for dynamic ultrasound scanning hinders deep application of AI technology in the ultrasound field. The Sono-Agent prototype proposed in this research attempts to construct a new human-AI collaborative workflow that can fully utilize AI technical advantages while maintaining and enhancing physician professional judgment capabilities. This represents a fundamental shift from AI as a diagnostic tool toward AI as an intelligent partner in clinical practice.

Comprehensively, this research is positioned at the intersection of medical AI, ultrasound diagnosis, and clinical decision support, aiming to provide a complete systematic solution for addressing the major clinical challenge of early diagnosis of gastric and pancreatic cancers through systematic theoretical innovation and technological breakthroughs. The research starting point encompasses not only technical advancement but also clinical practicality and translational value, striving to genuinely benefit patients and society while advancing academic frontiers. This comprehensive approach distinguishes the work from previous efforts that typically address isolated technical challenges without considering the full spectrum of clinical requirements and implementation challenges.

