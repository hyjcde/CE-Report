% !TEX root = ../thesis.tex

\chapter{USANet Framework Experimental Results and Analysis} \label{chp:usanet_results}

\section{Experimental Setup and Dataset Characteristics}

The comprehensive evaluation of USANet framework was conducted using a meticulously constructed multi-center dataset that represents one of the largest and most diverse collections of transabdominal ultrasound images for gastric and pancreatic cancer assessment. The dataset construction process spanned three years of collaborative efforts with eight tertiary medical centers across different geographical regions, ensuring representative diversity in patient demographics, ultrasound equipment variations, and scanning protocols. This extensive collaboration was essential to capture the natural variability present in real-world clinical practice and to ensure that our experimental results would generalize beyond single-institution settings.

The final dataset comprised 4,847 examination cases, including 2,156 gastric cancer cases and 1,691 pancreatic cancer cases, with the remaining cases representing benign conditions or normal anatomy. Each case contained comprehensive imaging data including high-resolution static images in DICOM format, dynamic scanning videos, and detailed clinical annotations verified by pathological examination. The temporal distribution of cases spanned from January 2018 to December 2023, with careful attention to maintaining consistent annotation quality despite the extended collection period. Patient demographics showed balanced representation across age groups, with particular emphasis on early-stage diseases that are most challenging for conventional diagnostic approaches.

The annotation process involved a rigorous three-tier validation system where each case received independent evaluation from three experienced ultrasound physicians, followed by consensus review for cases with disagreement. Inter-observer agreement measured by Fleiss' kappa coefficient achieved 0.82 for lesion detection, 0.78 for benign-malignant classification, and 0.85 for anatomical localization, indicating substantial agreement and high annotation quality. The annotation schema encompassed multiple levels of detail including pixel-level segmentation masks for clearly visible lesions, bounding box annotations for suspicious regions, ordinal classifications for echo characteristics and border definitions, and structured assessments of relationships with adjacent anatomical structures.

\section{Two-Stage Training Strategy Implementation and Results}

The implementation of the two-stage knowledge injection training strategy represented a critical innovation in addressing the unique challenges of ultrasound image analysis. The first stage of general abdominal representation pre-training utilized a substantially larger dataset of 15,000 unlabeled or weakly-labeled abdominal ultrasound videos collected from routine clinical practice. This pre-training phase employed a sophisticated combination of self-supervised learning objectives designed specifically for the characteristics of ultrasound imaging.

The self-supervised learning framework incorporated temporal consistency objectives that encouraged the model to learn stable representations across consecutive frames of ultrasound videos, effectively capturing the dynamic nature of ultrasound examination. Contrastive learning components helped the model distinguish between different anatomical regions and scanning approaches while identifying shared characteristics across different patients and equipment settings. Masked image modeling adapted for ultrasound characteristics taught the model to understand the relationship between different image regions and to reconstruct missing information based on context, a capability that proved particularly valuable for handling the variable image quality inherent in ultrasound imaging.

The first stage training required approximately 200 hours of computational time using four Tesla V100 GPUs, with careful hyperparameter tuning to balance learning stability and convergence speed. The resulting pre-trained encoder demonstrated remarkable capability in extracting meaningful features from ultrasound images, as evidenced by visualization analyses using techniques such as Grad-CAM and feature space clustering. These analyses revealed that the pre-trained model had learned to identify anatomical landmarks, tissue interfaces, and characteristic ultrasound patterns without explicit supervision, providing a strong foundation for subsequent disease-specific training.

The second stage of multi-task knowledge joint fine-tuning built upon this foundation by introducing task-specific heads for gastric and pancreatic cancer assessment. This stage utilized the carefully annotated dataset of cancer cases, with training designed to preserve the general representation capabilities while adapting to specific diagnostic tasks. The fine-tuning process employed a sophisticated learning rate scheduling strategy where the pre-trained encoder was updated with a learning rate one-tenth that of the task-specific heads, ensuring that valuable pre-learned representations were refined rather than overwritten.

Experimental validation of the two-stage training strategy demonstrated clear advantages over conventional end-to-end training approaches. Models trained using the two-stage strategy achieved convergence 40% faster than baseline approaches while requiring 25% fewer labeled training samples to reach equivalent performance levels. Most importantly, the two-stage models demonstrated superior generalization capabilities when evaluated on data from medical institutions not included in the training set, with performance degradation of only 3-5% compared to 12-18% for baseline models. This enhanced generalization represents a crucial advantage for clinical deployment where models must perform reliably across different institutions and equipment configurations.

\section{Multi-task Learning Performance Analysis}

The multi-task learning capabilities of USANet were evaluated through comprehensive experiments designed to assess both individual task performance and cross-task synergistic effects. The evaluation framework encompassed four primary assessment tasks: lesion localization using object detection metrics, precise segmentation measured by overlap coefficients, benign-malignant classification evaluated through discrimination metrics, and attribute assessment validated against pathological staging information.

For gastric cancer assessment, USANet achieved remarkable performance across all evaluation metrics. Lesion localization demonstrated mean Average Precision (mAP) of 0.847 at IoU threshold 0.5, representing a substantial improvement over single-task baselines that achieved mAP values ranging from 0.782 to 0.798. The improvement was particularly pronounced for challenging cases involving small lesions or complex anatomical backgrounds, where the unified framework's ability to leverage contextual information from adjacent organs provided decisive advantages. Segmentation performance yielded Dice coefficients of 0.831 for clearly defined lesions, with particularly strong performance for lesions larger than 10mm in diameter where detailed morphological analysis becomes clinically meaningful.

Benign-malignant classification for gastric lesions achieved Area Under the ROC Curve (AUC) of 0.912, with sensitivity of 89.3% and specificity of 87.6% at the optimal operating point determined by Youden's index. These performance metrics exceeded those of specialized single-task models by margins of 3-7%, with the improvement being most significant for borderline cases where morphological features alone proved insufficient for confident classification. The attribute assessment component successfully predicted pathological T-staging with correlation coefficient of 0.78 (p<0.001), demonstrating clinically meaningful capability to inform treatment planning decisions.

Pancreatic cancer assessment presented greater technical challenges due to the inherent difficulties of pancreatic visualization through transabdominal ultrasound, yet USANet achieved performance levels that exceeded expectations based on previous literature. Lesion localization achieved mAP of 0.789, which compared favorably to the range of 0.721-0.745 achieved by single-task models specifically optimized for pancreatic cancer detection. The unified framework's advantage was particularly evident in cases where pancreatic lesions were partially obscured by overlying gastric structures, demonstrating the value of joint modeling of anatomically related organs.

Segmentation of pancreatic lesions achieved Dice coefficients of 0.793, with performance showing strong correlation to lesion size and contrast characteristics. Benign-malignant classification reached AUC of 0.887, with sensitivity of 85.7% and specificity of 83.9%. While these metrics were slightly lower than those achieved for gastric cancer, they represented substantial improvements over existing approaches for pancreatic cancer assessment using transabdominal ultrasound. The attribute assessment for pancreatic cancer focused on vascular involvement and regional spread, achieving correlation coefficients of 0.72 with pathological staging, providing valuable information for surgical planning and treatment selection.

\section{Ablation Studies and Component Analysis}

Comprehensive ablation studies were conducted to isolate the contributions of different architectural components and training strategies, providing detailed insights into the mechanisms underlying USANet's superior performance. These studies followed rigorous experimental protocols with consistent training procedures and evaluation metrics, ensuring that observed differences could be attributed to specific design choices rather than experimental artifacts.

The impact of the two-stage training strategy was evaluated by comparing USANet models trained using the proposed approach against identical architectures trained end-to-end from randomly initialized weights. Results demonstrated that two-stage training provided consistent benefits across all evaluation metrics, with improvements ranging from 2.3% to 7.8% depending on the specific task and evaluation criterion. The benefits were most pronounced for tasks requiring fine-grained discrimination, such as benign-malignant classification and attribute assessment, suggesting that the pre-trained representations captured subtle visual patterns that proved crucial for these challenging tasks.

Architectural component analysis revealed the importance of the CNN-Transformer hybrid design for handling ultrasound image characteristics. Ablation studies comparing pure CNN architectures, pure Transformer architectures, and the hybrid approach demonstrated that each component contributed unique capabilities. CNN components excelled at extracting local texture features and handling the speckle noise characteristic of ultrasound images, while Transformer components provided superior capability for modeling long-range spatial relationships and integrating information across different anatomical regions.

The multi-task learning framework was evaluated by comparing the unified USANet architecture against ensembles of specialized single-task models. Results demonstrated that the unified approach achieved comparable or superior performance on individual tasks while requiring significantly fewer computational resources and providing better consistency across different evaluation scenarios. Task-specific ablation studies revealed that gastric cancer assessment tasks benefited most from pancreatic cancer information when lesions were located in anatomical regions where the two organs are adjacent, while pancreatic cancer assessment gained most from gastric information in cases where gastric filling provided acoustic windows for pancreatic visualization.

Loss function component analysis examined the contribution of different loss terms in the weighted composite objective function. Experiments with different weight configurations revealed that optimal performance required balanced attention to all task components, with weights determined through systematic grid search and validated through cross-validation procedures. Dynamic weight adjustment strategies were also evaluated, with uncertainty-based weighting showing modest improvements over fixed weight configurations, particularly during the early stages of training.

\section{Comparative Analysis with State-of-the-Art Methods}

USANet performance was comprehensively compared against multiple categories of baseline methods to establish its position relative to current state-of-the-art approaches. The comparison framework included both specialized medical imaging architectures and general-purpose computer vision models adapted for ultrasound analysis, ensuring broad coverage of relevant methodological approaches.

Comparison with specialized medical imaging architectures included prominent networks such as U-Net variants optimized for medical segmentation, ResNet architectures commonly used in medical classification tasks, and DenseNet models known for efficient feature reuse. These baselines were carefully implemented using identical training data and evaluation protocols to ensure fair comparison. Results demonstrated that USANet achieved superior performance across all major evaluation metrics, with particularly significant advantages in tasks requiring integration of information from multiple anatomical regions.

The comparison with general-purpose computer vision models included recent architectures such as EfficientNet variants known for optimal accuracy-efficiency trade-offs, Vision Transformer models representing the latest advances in attention-based architectures, and hybrid models combining convolutional and attention mechanisms. These comparisons were particularly important for establishing whether the medical domain-specific design choices in USANet provided genuine advantages over highly optimized general-purpose architectures. Results confirmed that domain-specific adaptations, particularly the two-stage training strategy and multi-task learning framework, provided substantial benefits that could not be replicated through simple architectural improvements alone.

Computational efficiency analysis revealed that USANet achieved its superior performance while maintaining reasonable computational requirements. Inference time analysis showed that USANet required 127ms per image on Tesla V100 hardware, compared to 89-156ms for baseline architectures, representing acceptable overhead considering the additional functionality provided by the multi-task framework. Memory usage analysis indicated that USANet required approximately 30% more GPU memory than single-task baselines, but this increase was more than offset by the elimination of separate models for different tasks.

\section{Clinical Significance and Translational Implications}

The experimental results demonstrated that USANet achieved performance levels that approach and in some cases exceed those reported for human experts in similar diagnostic tasks, suggesting genuine potential for clinical translation and impact. Performance analysis across different disease stages revealed that USANet showed particular strength in early-stage disease detection, where conventional diagnostic approaches face the greatest challenges and where clinical impact would be most significant.

For gastric cancer assessment, USANet demonstrated capability to detect lesions with mean diameter as small as 8.7mm with reasonable reliability, representing a substantial improvement over previous automated approaches that typically required lesions larger than 15mm for confident detection. This enhanced sensitivity for small lesions has direct implications for screening applications, where early detection capabilities determine the ultimate clinical value of any diagnostic technology. The system's ability to provide consistent performance across different ultrasound equipment manufacturers and imaging protocols addresses a critical barrier to widespread clinical deployment.

Pancreatic cancer assessment results were particularly encouraging given the notorious difficulty of pancreatic visualization through transabdominal ultrasound. USANet's capability to achieve reliable detection performance even in cases with suboptimal acoustic windows suggests potential for expanding the clinical utility of transabdominal ultrasound in pancreatic cancer screening and surveillance. The integration of gastric information to improve pancreatic assessment represents a novel approach that could reshape clinical examination protocols and optimize the diagnostic yield of abdominal ultrasound examinations.

Error analysis revealed that USANet failures typically occurred in cases that would also challenge experienced human interpreters, such as cases with extensive artifact interference, extremely subtle morphological changes, or complex anatomical variants. This pattern suggests that USANet has learned to recognize the same visual cues that human experts rely upon, rather than exploiting spurious correlations or dataset-specific artifacts that would limit clinical generalizability.

The demonstration that unified multi-task learning can outperform specialized single-task approaches has broader implications for medical AI development beyond ultrasound imaging. The results suggest that artificial fragmentation of naturally integrated clinical tasks may be counterproductive and that AI systems designed to mirror the holistic reasoning patterns of experienced clinicians may achieve superior performance while reducing implementation complexity. These findings support a paradigm shift toward more integrated, contextually aware medical AI systems that can better serve the complex, multifaceted nature of clinical practice.
